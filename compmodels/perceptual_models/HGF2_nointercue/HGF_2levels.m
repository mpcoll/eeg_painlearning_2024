function [traj, infStates] = HGF_2levels(r, p, varargin)
% Calculates the trajectories of the agent's representations under the HGF
%
% This function can be called in two ways:
% 
% (1) tapas_hgf_binary(r, p)
%   
%     where r is the structure generated by tapas_fitModel and p is the parameter vector in native space;
%
% (2) tapas_hgf_binary(r, ptrans, 'trans')
% 
%     where r is the structure generated by tapas_fitModel, ptrans is the parameter vector in
%     transformed space, and 'trans' is a flag indicating this.
%
% --------------------------------------------------------------------------------------------------
% Copyright (C) 2012-2017 Christoph Mathys, TNU, UZH & ETHZ
%
% This file is part of the HGF toolbox, which is released under the terms of the GNU General Public
% Licence (GPL), version 3. You can redistribute it and/or modify it under the terms of the GPL
% (either version 3 or, at your option, any later version). For further details, see the file
% COPYING or <http://www.gnu.org/licenses/>.



% Get the number of cues

% Transform paramaters back to their native space if needed
if ~isempty(varargin) && strcmp(varargin{1},'trans');
    p = HGF_2levels_transp(r, p);
end


% Number of levels
try
    l = r.c_prc.n_levels;
catch
    l = (length(p)+1)/5;
    
    if l ~= floor(l)
        error('tapas:hgf:UndetNumLevels', 'Cannot determine number of levels');
    end
end

% Unpack parameters
mu_0 = p(1:l);
sa_0 = p(l+1:2*l);
rho  = p(2*l+1:3*l);
ka   = p(3*l+1:4*l-1);
om   = p(4*l:5*l-2);
th   = exp(p(5*l-1));

% Add dummy "zeroth" trial
u = r.u(:,1);
c = r.u(:, 2);

% Number of cues (or # of independent HGF)
nc = max(c);
trials = length(c);


% Initialize trajectories
traj = struct;
traj.muhat = NaN(trials, 3);
traj.sahat = NaN(trials, 3);
traj.mu = NaN(trials, 3);
traj.sa = NaN(trials, 3);
traj.v = NaN(trials, 3);
traj.w = NaN(trials, 2);
traj.da = NaN(trials, 3);
traj.psi = NaN(trials, 3);
traj.ud = NaN(trials, 3);
traj.epsi = NaN(trials, 3);
traj.wt = NaN(trials, 3);

% Run the HGF for each cue
for cue = 1:nc
    
    % trials number for this cue
    ctrials = find(c==cue);

    % cue specific reinforcement
    o = [0 ;u(c==cue)];
    % Number of trials wiht this cue
    n = length(o);
    t = ones(n,1);

    % Representations
    mu = NaN(n,l); 
    pi = NaN(n,l);

    % Other quantities
    muhat = NaN(n,l);
    pihat = NaN(n,l);
    v     = NaN(n,l);

    w     = NaN(n,l-1);
    da    = NaN(n,l);

    % Representation priors
    % Note: first entries of the other quantities remain
    % NaN because they are undefined and are thrown away
    % at the end; their presence simply leads to consistent
    % trial indices.
%     muhat(1,1) = tapas_sgm(mu_0(2), 1);
%     pihat(1,1) = 1/(muhat(1,1)*(1 -muhat(1,1)));
    mu(1,1) = 0;
    pi(1,1) = Inf;
    mu(1,2:end) = mu_0(2:end);
    pi(1,2:end) = 1./sa_0(2:end);

    % Pass through representation update loop
    for k = 2:1:n
            %%%%%%%%%%%%%%%%%%%%%%
            % Effect of input u(k) for cue c(k)
            %%%%%%%%%%%%%%%%%%%%%%

            % 2nd level prediction
            muhat(k,2) = mu(k-1,2) +t(k) *rho(2);

            % 1st level
            % ~~~~~~~~~
            % Prediction
            muhat(k,1) = tapas_sgm(ka(1) *muhat(k,2), 1);

            % Precision of prediction
            pihat(k,1) = 1/(muhat(k,1)*(1 -muhat(k,1)));

            % Updates
            pi(k,1) = Inf;
            mu(k,1) = o(k);

            % Prediction error
            da(k,1) = mu(k,1) -muhat(k,1);

            % 2nd level
            % ~~~~~~~~~
            % Prediction: see above

            % Precision of prediction
            pihat(k,2) = 1/(1/pi(k-1,2) +exp(ka(2) *mu(k-1,3) +om(2)));

            % Updates
            pi(k,2) = pihat(k,2) +ka(1)^2/pihat(k,1);
            mu(k,2) = muhat(k,2) +ka(1)/pi(k,2) *da(k,1);

            % Volatility prediction error
            da(k,2) = (1/pi(k,2) +(mu(k,2) -muhat(k,2))^2) *pihat(k,2) -1;

            % Last level
            % ~~~~~~~~~~
            % Prediction
            muhat(k,3) = mu(k-1,3) +t(k) *rho(l);

            % Precision of prediction
            pihat(k,3) = 1/(1/pi(k-1,3) +t(k) *th);

            % Weighting factor
            v(k,3)   = t(k) *th;
            v(k,3-1) = t(k) *exp(ka(3-1) *mu(k-1,3) +om(3-1));
            w(k,3-1) = v(k,3-1) *pihat(k,3-1);

            % Updates
            pi(k,3) = pihat(k,3) +1/2 *ka(3-1)^2 *w(k,3-1) *(w(k,3-1) +(2 *w(k,3-1) -1) *da(k,3-1));

            if pi(k,3) <= 0
                error('tapas:hgf:NegPostPrec', 'Negative posterior precision. Parameters are in a region where model assumptions are violated.');
            end

            mu(k,3) = muhat(k,3) +1/2 *1/pi(k,3) *ka(3-1) *w(k,3-1) *da(k,3-1);

            % Volatility prediction error
            da(k,3) = (1/pi(k,3) +(mu(k,3) -muhat(k,3))^2) *pihat(k,3) -1;

    end

    % Implied learning rate at the first level
    sgmmu2 = tapas_sgm(ka(1) *mu(:,2), 1);
    dasgmmu2 = o -sgmmu2;
    lr1    = diff(sgmmu2)./dasgmmu2(2:n,1);
    lr1(da(2:n,1)==0) = 0;
    
    % Remove priors
    mu(1,:)  = [];
    pi(1,:)  = [];
    
    % Check validity of trajectories
    if any(isnan(mu(:))) || any(isnan(pi(:)))
        error('tapas:hgf:VarApproxInvalid', 'Variational approximation invalid. Parameters are in a region where model assumptions are violated.');
    else
        % Check for implausible jumps in trajectories
        dmu = diff(mu(:,2:end));
        dpi = diff(pi(:,2:end));
        rmdmu = repmat(sqrt(mean(dmu.^2)),length(dmu),1);
        rmdpi = repmat(sqrt(mean(dpi.^2)),length(dpi),1);

        jumpTol = 16;
        if any(abs(dmu(:)) > jumpTol*rmdmu(:)) || any(abs(dpi(:)) > jumpTol*rmdpi(:))
            error('tapas:hgf:VarApproxInvalid', 'Variational approximation invalid. Parameters are in a region where model assumptions are violated.');
        end
    end

    % Remove other priors
    muhat(1,:) = [];
    pihat(1,:) = [];
    v(1,:)     = [];
    w(1,:)     = [];
    da(1,:)    = [];

    % Create result data structure
    traj.mu(ctrials, :) = mu;
    
    traj.sa(ctrials,:) = 1./pi;

    traj.muhat(ctrials, :) = muhat;
    traj.sahat(ctrials, :) = 1./pihat;

    traj.v(ctrials, :)      = v;
    traj.w(ctrials, :)      = w;
    traj.da(ctrials, :)     = da;

    % Updates with respect to prediction
    traj.ud(ctrials, :) = mu -muhat;

    % Psi (precision weights on prediction errors)
    psi        = NaN(n-1,l);
    psi(:,2)   = 1./pi(:,2);
    psi(:,3:l) = pihat(:,2:l-1)./pi(:,3:l);
    traj.psi(ctrials, :)   = psi;

    % Epsilons (precision-weighted prediction errors)
    epsi        = NaN(n-1,l);
    epsi(:,2:l) = psi(:,2:l) .*da(:,1:l-1);
    traj.epsi(ctrials, :)   = epsi;

    % Full learning rate (full weights on prediction errors)
    wt        = NaN(n-1,l);
    wt(:,1)   = lr1;
    wt(:,2)   = psi(:,2);
    wt(:,3:l) = 1/2 *(v(:,2:l-1) *diag(ka(2:l-1))) .*psi(:,3:l);
    traj.wt(ctrials, :)   = wt;
end


% Create matrices for use by the observation model
infStates = NaN(trials,l,4);
infStates(:,:,1) = traj.muhat;
infStates(:,:,2) = traj.sahat;
infStates(:,:,3) = traj.mu;
infStates(:,:,4) = traj.sa;

return;
